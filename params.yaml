data_params:
  val_ratio: 0.1
  max_seqs_num: 50000
  min_seq_len: 20
  max_seq_len: 512
  # This batch size is used for embedding calculation
  embed_calc_batch_size: 64
  shuffle: true
  shuffle_seed: 23
  filter_skip_n: 0

distill_params:
  dataloader_num_workers: 4

  # student
  student_embed_dim: 512
  student_num_layers: 6
  student_num_heads: 8

  on_the_fly: false
  num_epochs: 10
  batch_size: 256

  # scheduler
  ## warmup
  start_lr: 1e-8
  warmup_steps: 128

  ## cosine annealing
  min_lr: 1e-5
  max_lr: 1e-3
  T_0: 75
  T_mult: 1.2
  gamma: 0.25


### DO NOT CHANGE CONFIGS BELOW ###
data_dirs:
  base_dir: "output/data"
  raw_dir: "output/data/raw"
  filter_split_dir: "output/data/filter_split"
  protx_dataset_dir: "output/data/protx_dataset"

  uniref50_url: "https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref50/uniref50.fasta.gz" 
  uniref50_fasta_gz: "output/data/raw/uniref50.fasta.gz"
  uniref50_fasta: "output/data/raw/uniref50.fasta"

  shuffled_fasta_file: "output/data/raw/uniref50_shuffled.fasta"

  uniref50_filtered_fasta: "output/data/filter_split/uniref50_filtered.fasta"
  train_fasta: "output/data/filter_split/train.fasta"
  val_fasta: "output/data/filter_split/val.fasta"
  info_file: "output/data/filter_split/dataset_info.txt"

  protx_train_prefix: "output/data/protx_dataset/train/train.h5"
  protx_val_prefix: "output/data/protx_dataset/val/val.h5"

  wandb_checkpoints_dir: "output/wandb_checkpoints"
  plots_dir: "output/checkpoints/plots"
